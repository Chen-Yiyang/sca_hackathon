{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7c08ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iycsp\\.conda\\envs\\deep-cuda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches # for bounding box\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.detection\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.ElementTree as ET \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e203f",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c741e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f2fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = Path(\"data/\")\n",
    "CHECKPOINT_PATH = \"checkpoints/\"\n",
    "# RESULTS_PATH = Path(\"results/\")\n",
    "\n",
    "def save_random_indices(rand_indices):\n",
    "    with open(CHECKPOINT_PATH + \"indices.npy\", 'wb') as f:\n",
    "        np.save(f, rand_indices)\n",
    "\n",
    "def get_random_indices(is_get_new=False):\n",
    "    if is_get_new:\n",
    "        rand_indices = np.random.permutation(np.arange(total_len))\n",
    "        return rand_indices\n",
    "            \n",
    "    try:\n",
    "        rand_indices = np.load(CHECKPOINT_PATH + \"indices.npy\")\n",
    "        print(\"[V] Load saved random indices\")\n",
    "        return rand_indices\n",
    "    except:\n",
    "        print(\"[E] Unable to load saved random indices\")\n",
    "        return None\n",
    "    \n",
    "def save_model_checkpoint(model, epoch, loss):\n",
    "    cp_name = f\"model_{epoch:02d}.pt\"\n",
    "    full_file_name = CHECKPOINT_PATH + cp_name\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f5570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3479, 3, 176, 240), (3479, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.load(\"./Datasets/processed_all_input_reduced.npy\")\n",
    "df = pd.read_csv(\"./Datasets/processed_all_output_reduced.csv\")  # output\n",
    "inputs.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64a9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df['label'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe321f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gpu_usage():\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a838d5",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fc6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] Load saved random indices\n"
     ]
    }
   ],
   "source": [
    "# shuffle and prepare for train test split\n",
    "TRAIN_RATIO = 0.8\n",
    "total_len = inputs.shape[0]\n",
    "train_len = math.floor(total_len * TRAIN_RATIO)\n",
    "\n",
    "rand_indices = get_random_indices()\n",
    "train_indices, test_indices = rand_indices[:train_len], rand_indices[train_len:]\n",
    "\n",
    "#  = torch.Tensor(inputs[:train_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3c56f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-TRAIN=torch.Size([2783, 3, 176, 240])\tX-TEST=torch.Size([696, 3, 176, 240])\n"
     ]
    }
   ],
   "source": [
    "# x data\n",
    "x_train, x_test = torch.Tensor(inputs[train_indices]), torch.Tensor(inputs[test_indices])\n",
    "del inputs\n",
    "\n",
    "print(f\"X-TRAIN={x_train.shape}\\tX-TEST={x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54dbb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_random_indices(rand_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050ef95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: TRAIN=torch.Size([2783, 1])\tTEST=torch.Size([696, 1])\n",
      "BOXES: TRAIN=torch.Size([2783, 1, 4])\tTEST=torch.Size([696, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "labels = np.array(df['label'])\n",
    "labels = np.expand_dims(labels, 1)\n",
    "labels_train, labels_test = torch.LongTensor(labels[train_indices]), torch.LongTensor(labels[test_indices])\n",
    "\n",
    "# boxes\n",
    "boxes_np = np.array(df[['x1', 'y1', 'x2', 'y2']])\n",
    "boxes_np = np.expand_dims(boxes_np, 1)\n",
    "boxes_np = boxes_np# TODO:??? / 256\n",
    "# boxes_all = torch.Tensor(boxes_np)\n",
    "boxes_train, boxes_test = torch.Tensor(boxes_np[train_indices]), torch.Tensor(boxes_np[test_indices])\n",
    "\n",
    "print(f\"LABEL: TRAIN={labels_train.shape}\\tTEST={labels_test.shape}\")\n",
    "print(f\"BOXES: TRAIN={boxes_train.shape}\\tTEST={boxes_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43be09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concate labels and boxes\n",
    "targets_train = []\n",
    "for i in range(train_len):\n",
    "    d = {}\n",
    "    d['boxes'] = boxes_train[i].to(device)\n",
    "    d['labels'] = labels_train[i].to(device)\n",
    "    targets_train.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0291a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.002654GB\n",
      "torch.cuda.memory_reserved: 0.003906GB\n",
      "torch.cuda.max_memory_reserved: 0.003906GB\n"
     ]
    }
   ],
   "source": [
    "show_gpu_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a86a5c",
   "metadata": {},
   "source": [
    "# Use Helper Functions from PyTorch repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd644f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/vision.git\n",
    "# %cd vision\n",
    "# !git checkout v0.3.0\n",
    "\n",
    "# !cp references/detection/utils.py ../\n",
    "# !cp references/detection/transforms.py ../\n",
    "# !cp references/detection/coco_eval.py ../\n",
    "# !cp references/detection/engine.py ../\n",
    "# !cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d88c4",
   "metadata": {},
   "source": [
    "# Develop Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92f1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_func():\n",
    "#     model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "#             weights = torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT).to(device)\n",
    "\n",
    "    # load a model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes) \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27a0eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iycsp\\.conda\\envs\\deep-cuda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\iycsp\\.conda\\envs\\deep-cuda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model, criterion, optimizer = init_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f301198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_freeze(model):\n",
    "    for name, child in model.named_children():\n",
    "        if name == 'box_predictor':\n",
    "            print(\"[V] Last layer, need grad\")\n",
    "            print(child)\n",
    "            continue\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        dfs_freeze(child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a303e000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] Last layer, need grad\n",
      "FastRCNNPredictor(\n",
      "  (cls_score): Linear(in_features=1024, out_features=20, bias=True)\n",
      "  (bbox_pred): Linear(in_features=1024, out_features=80, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dfs_freeze(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d4aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_train[1:2].to(device), targets_train[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b314f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(3.0975, device='cuda:0'),\n",
       " 'loss_box_reg': tensor(0.0010, device='cuda:0'),\n",
       " 'loss_objectness': tensor(3.3457, device='cuda:0'),\n",
       " 'loss_rpn_box_reg': tensor(1.1285, device='cuda:0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757306cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHES = 5\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f412bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = x_train.mean(), x_train.std()\n",
    "mean = mean.to(device)\n",
    "std = std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e857f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.160921GB\n",
      "torch.cuda.memory_reserved: 0.660156GB\n",
      "torch.cuda.max_memory_reserved: 0.660156GB\n"
     ]
    }
   ],
   "source": [
    "show_gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a324bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 696/696 [06:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 6.0345127781232195 min \t loss= 5.61336956216001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 696/696 [06:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 2 \t time= 12.081812365849812 min \t loss= 5.613787738756201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 696/696 [06:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 3 \t time= 18.127878268559773 min \t loss= 5.61401474818416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 696/696 [06:04<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 4 \t time= 24.207811244328816 min \t loss= 5.6139672652058215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1,NUM_EPOCHES):\n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    # set the order in which to visit the image from the training set\n",
    "    shuffled_indices=torch.randperm(train_len)\n",
    " \n",
    "    for count in tqdm(range(0, train_len, bs)):\n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch       \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data    = x_train[indices].to(device)\n",
    "        minibatch_targets = [targets_train[idx] for idx in indices]\n",
    "#         minibatch_data = x_train[count:count+bs]\n",
    "#         minibatch_targets = targets_train[count:count+bs]\n",
    "        \n",
    "        # send them to the gpu\n",
    "#         minibatch_data    = minibatch_data.to(device)\n",
    "#         minibatch_targets = minibatch_targets.to(device)\n",
    "        \n",
    "        # normalize the minibatch (this is the only difference compared to before!)\n",
    "        inputs = (minibatch_data - mean) / std \n",
    "        \n",
    "        # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        # forward the minibatch through the net and get loss\n",
    "        loss_dict = model(inputs, minibatch_targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "        losses.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # START COMPUTING STATS\n",
    "        \n",
    "        # add the loss of this batch to the running loss\n",
    "        running_loss += losses.detach().item()\n",
    "        \n",
    "        # compute the error made on this batch and add it to the running error       \n",
    "#         error = utils.get_error( scores.detach() , minibatch_label)\n",
    "#         running_error += error.item()\n",
    "        \n",
    "        num_batches+=1\n",
    "    \n",
    "    \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "#     total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed, 'min', '\\t loss=', total_loss)\n",
    "    \n",
    "    save_model_checkpoint(model, epoch, total_loss)\n",
    "    \n",
    "\n",
    "#     print('epoch=',epoch, '\\t time=', elapsed,'min','\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "#     eval_on_test_set() \n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f5171",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(ep_id):\n",
    "    model, criterion, optimizer = init_func()\n",
    "    \n",
    "    cp_name = f\"model_{ep_id:02d}.pt\"\n",
    "    full_file_name = CHECKPOINT_PATH + cp_name\n",
    "    checkpoint = torch.load(full_file_name)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCH_ID = 4\n",
    "model = load_checkpoint(EPOCH_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e98f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45c4f733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 176, 240])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de3a35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = x_test[0:1].to(device)\n",
    "\n",
    "predictions = model(test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf808972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 90.6460,  56.0403, 139.5947, 128.8039], device='cuda:0'), 4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predictions[0]\n",
    "box = pred['boxes'][0]\n",
    "label = pred['labels'][0].item()\n",
    "\n",
    "box, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9365d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_img(img_np, box):\n",
    "    img = img_np * 256\n",
    "    img = Image.fromarray(img.astype(np.uint8))\n",
    "    x1, y1, x2, y2 = box\n",
    "\n",
    "    # plot img and bbox\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93d664fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1, box1 = show_img(x_test[0].to(device), box, label)\n",
    "# visualise_img(img1, box1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee0504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ece2cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint_light(model):\n",
    "    cp_name = f\"model_light_{epoch:02d}.pt\"\n",
    "    full_file_name = CHECKPOINT_PATH + cp_name\n",
    "    torch.save({'model_state_dict': model.state_dict()}, full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "da33e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_checkpoint_light(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f2684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deep-cuda] *",
   "language": "python",
   "name": "conda-env-.conda-deep-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
